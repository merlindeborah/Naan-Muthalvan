{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QtH5FufT3JH",
        "outputId": "c03f4377-4874-4104-db5c-893618c53063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: transformers 4.35.2\n",
            "Uninstalling transformers-4.35.2:\n",
            "  Successfully uninstalled transformers-4.35.2\n",
            "\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting transformers[torch]\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.11 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate, transformers\n",
            "Successfully installed accelerate-0.27.2 transformers-4.37.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall transformers accelerate -y\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3S_UM_GTWl2",
        "outputId": "fe74644d-fbee-4a3a-ae3e-754ad1f60d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y2Q8WGUPZnT",
        "outputId": "d41d94a3-39e1-44ff-ba49-a7db8ddf7191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ajaUeaRPuUa"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj272HB0eYux",
        "outputId": "6f01fa7b-5ba7-4365-8257-6db269458d39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-15 01:56:39--  https://drive.google.com/file/d/1YOZVY6uDW6DjIIQ55AE48RXbpyfTWuXR/view?usp=drive_link\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.199.138, 74.125.199.102, 74.125.199.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.199.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view?usp=drive_link.1’\n",
            "\n",
            "view?usp=drive_link     [ <=>                ]  83.00K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-02-15 01:56:40 (17.8 MB/s) - ‘view?usp=drive_link.1’ saved [84992]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://drive.google.com/file/d/1YOZVY6uDW6DjIIQ55AE48RXbpyfTWuXR/view?usp=drive_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0ZftjOFPxpV"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wkpDoWUP7s0",
        "outputId": "00a500e2-a9b7-4f2a-fb0c-05b2681d6ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading amazon-fine-food-reviews.zip to /content\n",
            " 97% 235M/242M [00:01<00:00, 182MB/s]\n",
            "100% 242M/242M [00:01<00:00, 162MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d snap/amazon-fine-food-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6D8ln0mP-nV",
        "outputId": "2d5b6661-6062-4391-d0b3-b5dfed07cf98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/amazon-fine-food-reviews.zip\n",
            "  inflating: Reviews.csv             \n",
            "  inflating: database.sqlite         \n",
            "  inflating: hashes.txt              \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/amazon-fine-food-reviews.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "EN-jsgtYafQC",
        "outputId": "c0dc8328-9c3d-4e5d-d34e-56bdf77f4e31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [87/87 50:34, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('fine_tuned_summarizer_tokenizer/tokenizer_config.json',\n",
              " 'fine_tuned_summarizer_tokenizer/special_tokens_map.json',\n",
              " 'fine_tuned_summarizer_tokenizer/spiece.model',\n",
              " 'fine_tuned_summarizer_tokenizer/added_tokens.json')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "\n",
        "dataset_path = 'Reviews.csv'\n",
        "df = pd.read_csv(dataset_path, nrows=500)\n",
        "\n",
        "train_texts, val_texts, train_summaries, val_summaries = train_test_split(\n",
        "    df['Text'].tolist(), df['Summary'].tolist(), test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, max_length=512, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, max_length=512, truncation=True, padding=True)\n",
        "\n",
        "train_labels = tokenizer(train_summaries, max_length=150, truncation=True, padding=True)\n",
        "val_labels = tokenizer(val_summaries, max_length=150, truncation=True, padding=True)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "val_dataset = CustomDataset(val_encodings, val_labels)\n",
        "\n",
        "def data_collator(batch):\n",
        "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
        "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
        "    labels = torch.stack([item['labels'] for item in batch])\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    save_steps=250,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=250,\n",
        "    save_total_limit=3,\n",
        "    overwrite_output_dir=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"fine_tuned_summarizer_model\")\n",
        "tokenizer.save_pretrained(\"fine_tuned_summarizer_tokenizer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOrT3fDRekZK"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/fine_tuned_summarizer_tokenizer /content/drive/MyDrive/Ideathan/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JTCzE-L0T8c",
        "outputId": "ca34fbad-956c-45f8-d122-44e34b17b58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Summary of Reviews:\n",
            "the pizza i ordered was compratively cheap than I expected. the burger was overcooked, and the fries were soggy. not worth the price. the sauce lacked flavor, and the noodles were overcooked.\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/Ideathan/fine_tuned_summarizer_model\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/drive/MyDrive/Ideathan/fine_tuned_summarizer_tokenizer\")\n",
        "\n",
        "reviews = [\n",
        "    \"The prize of the pizza i ordered was compratively cheap than I expected\",\n",
        "    \"I ordered the burger with fries, and it was disappointing. The burger was overcooked, and the fries were soggy. Not worth the price.\",\n",
        "    \"The sushi was incredible! Fresh fish and perfectly seasoned rice. Will be my go-to sushi spot from now on.\",\n",
        "    \"The pasta was underwhelming. The sauce lacked flavor, and the noodles were overcooked. Won't be returning.\",\n",
        "    \"The steak was cooked to perfection! Juicy and flavorful, just the way I like it.\"\n",
        "]\n",
        "review_summaries = []\n",
        "for review in reviews:\n",
        "    inputs = tokenizer.encode(\"summarize: \" + review, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(inputs, max_length=50, min_length=5, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    review_summaries.append(summary)\n",
        "\n",
        "overall_summary = \" \".join(review_summaries)\n",
        "\n",
        "inputs = tokenizer.encode(\"summarize: \" + overall_summary, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "outputs = model.generate(inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "final_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Overall Summary of Reviews:\")\n",
        "print(final_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aWdIEGNcBGk",
        "outputId": "fc9fcaee-0c3b-4052-c7c5-e3685fcafb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  app.zip\n",
            "  inflating: app.py                  \n",
            "  inflating: book.html               \n",
            "  inflating: index.html              \n",
            "  inflating: menu.html               \n",
            "  inflating: review.html             \n",
            "  inflating: reviews.csv             \n",
            "  inflating: static/css/bootstrap.css  \n",
            "  inflating: static/css/font-awesome.min.css  \n",
            "  inflating: static/css/responsive.css  \n",
            "  inflating: static/css/style.css    \n",
            "  inflating: static/css/style.css.map  \n",
            "  inflating: static/css/style.scss   \n",
            "  inflating: static/fonts/fontawesome-webfont.ttf  \n",
            "  inflating: static/fonts/fontawesome-webfont.woff  \n",
            "  inflating: static/fonts/fontawesome-webfont.woff2  \n",
            "  inflating: static/images/about-img.png  \n",
            "  inflating: static/images/client1.jpg  \n",
            "  inflating: static/images/client2.jpg  \n",
            "  inflating: static/images/f1.png    \n",
            "  inflating: static/images/f2.png    \n",
            "  inflating: static/images/f3.png    \n",
            "  inflating: static/images/f4.png    \n",
            "  inflating: static/images/f5.png    \n",
            "  inflating: static/images/f6.png    \n",
            "  inflating: static/images/f7.png    \n",
            "  inflating: static/images/f8.png    \n",
            "  inflating: static/images/f9.png    \n",
            "  inflating: static/images/favicon.png  \n",
            "  inflating: static/images/hero-bg.jpg  \n",
            "  inflating: static/images/o1.jpg    \n",
            "  inflating: static/images/o2.jpg    \n",
            "  inflating: static/js/bootstrap.js  \n",
            "  inflating: static/js/custom.js     \n",
            "  inflating: static/js/jquery-3.4.1.min.js  \n",
            "  inflating: templates/about.html    \n",
            "  inflating: templates/book.html     \n",
            "  inflating: templates/index.html    \n",
            "  inflating: templates/menu.html     \n",
            "  inflating: templates/review.html   \n"
          ]
        }
      ],
      "source": [
        "!unzip app.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3CPVKUzc4Qb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKKxMe6TbecJ",
        "outputId": "4297d474-65fb-4914-fc74-3e8f075f6e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GKkkw_4SyJK",
        "outputId": "8d1b1b36-c275-4afc-8a63-92cbb75fc63f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2b7Ilnk9Ki0v9Rm63sKaZzJrNzl_6rKfcUhpchy3LbtwZqhyH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSdu-7VjcgXv",
        "outputId": "214547c4-f223-4e5e-dbad-e80ee1b66f20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Tunnel URL: NgrokTunnel: \"https://df06-34-42-134-62.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, render_template\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import csv\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "ngrok.kill()\n",
        "def start_ngrok():\n",
        "    ngrok_address = ngrok.connect(5000)\n",
        "    print(' * Tunnel URL:', ngrok_address)\n",
        "\n",
        "threading.Thread(target=start_ngrok).start()\n",
        "app = Flask(__name__)\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/Ideathan/fine_tuned_summarizer_model\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/drive/MyDrive/Ideathan/fine_tuned_summarizer_tokenizer\")\n",
        "def add_review_to_csv(food_item, review):\n",
        "    with open('reviews.csv', mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([food_item, review])\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('review.html')\n",
        "\n",
        "@app.route('/submit_review', methods=['POST'])\n",
        "def submit_review():\n",
        "    food_item = request.form['food_item']\n",
        "    review = request.form['review']\n",
        "    add_review_to_csv(food_item, review)\n",
        "    return render_template('review.html')\n",
        "\n",
        "@app.route('/summarize', methods=['POST'])\n",
        "def summarize():\n",
        "    reviews = []\n",
        "    with open('reviews.csv', newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            reviews.append(row['REVIEW'])\n",
        "    review_summaries = []\n",
        "    for review in reviews:\n",
        "        inputs = tokenizer.encode(\"summarize: \" + review, return_tensors=\"pt\", max_length=50, truncation=True)\n",
        "        outputs = model.generate(inputs, max_length=50, min_length=10, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        review_summaries.append(summary)\n",
        "    overall_summary = \" \".join(review_summaries)\n",
        "    inputs = tokenizer.encode(\"summarize: \" + overall_summary, return_tensors=\"pt\", max_length=50, truncation=True)\n",
        "    outputs = model.generate(inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    final_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return final_summary\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
